{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cef513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, SeparableConv2D\n",
    "from tensorflow.keras.layers import Add, GlobalAveragePooling2D, Dense, Dropout, Multiply\n",
    "from tensorflow.keras.layers import GroupNormalization, Conv1D, AveragePooling2D, Concatenate, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abd8bf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 920 CK+ images with 7 classes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image):\n",
    "    img = cv2.resize(image, (227, 227))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "def load_ckplus_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path, on_bad_lines='skip')  # Skip malformed lines\n",
    "    images, labels = [], []\n",
    "    class_map = {0: 'anger', 1: 'contempt', 2: 'disgust', 3: 'fear', 4: 'happiness', 5: 'sadness', 6: 'surprise'}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            pixels = np.array(row['pixels'].split(), dtype=np.uint8).reshape(48, 48)\n",
    "            images.append(preprocess_image(pixels))\n",
    "            labels.append(int(row['emotion']))\n",
    "        except (ValueError, IndexError) as e:\n",
    "            print(f\"Skipping invalid row due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(f\"Loaded {len(images)} CK+ images with 7 classes\")\n",
    "    return images, labels\n",
    "\n",
    "# Load CK+\n",
    "ck_path = \"/Users/adicadi/.cache/kagglehub/datasets/davilsena/ckdataset/versions/2/ckextended.csv\"\n",
    "ck_images, ck_labels = load_ckplus_from_csv(ck_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e16a631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1106 images.\n",
      "Loaded 1106 KMU-FED images with 6 classes (expected 1106)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def load_kmu_fed(folder_path):\n",
    "    images, labels = [], []\n",
    "    emotion_map = {\n",
    "        'AN': 0,  # Anger\n",
    "        'DI': 1,  # Disgust\n",
    "        'FE': 2,  # Fear\n",
    "        'HA': 3,  # Happiness\n",
    "        'SA': 4,  # Sadness\n",
    "        'SU': 5   # Surprise\n",
    "    }\n",
    "    \n",
    "    extensions = ('*.jpg', '*.jpeg', '*.png')\n",
    "    img_files = []\n",
    "    for ext in extensions:\n",
    "        img_files.extend(glob(os.path.join(folder_path, ext)))\n",
    "    \n",
    "    if not img_files:\n",
    "        print(f\"No image files found in {folder_path}. Check dataset structure.\")\n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "    print(f\"Found {len(img_files)} images.\")\n",
    "    for img_path in img_files:\n",
    "        filename = os.path.basename(img_path)\n",
    "        emotion_code = filename.split('_')[1]  # Extract emotion (e.g., 'AN' from '12_AN_gu_185.jpg')\n",
    "        if emotion_code in emotion_map:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                images.append(preprocess_image(img))\n",
    "                labels.append(emotion_map[emotion_code])\n",
    "        else:\n",
    "            print(f\"Unknown emotion code {emotion_code} in {filename}\")\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(f\"Loaded {len(images)} KMU-FED images with 6 classes (expected 1106)\")\n",
    "    if len(images) < 1106:\n",
    "        print(\"Warning: Missing images. Dataset may be incomplete or partially downloaded.\")\n",
    "    return images, labels\n",
    "\n",
    "# Load KMU-FED\n",
    "kmu_path = \"/Users/adicadi/.cache/kagglehub/datasets/anandpanajkar/kmu-fed/versions/1\"\n",
    "kmu_images, kmu_labels = load_kmu_fed(kmu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4daf975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 920 CK+ images with 7 classes (using 920)\n",
      "Skipped 0 rows due to errors.\n",
      "Found 1106 images.\n",
      "Loaded 1106 KMU-FED images with 6 classes (expected 1106)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_image(image):\n",
    "    img = cv2.resize(image, (227, 227))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Load CK+ dataset (using 920 images)\n",
    "def load_ckplus_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path, on_bad_lines='warn')\n",
    "    images, labels = [], []\n",
    "    skipped_rows = 0\n",
    "    class_map = {0: 'anger', 1: 'contempt', 2: 'disgust', 3: 'fear', 4: 'happiness', 5: 'sadness', 6: 'surprise'}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            pixels = np.array(row['pixels'].split(), dtype=np.uint8).reshape(48, 48)\n",
    "            images.append(preprocess_image(pixels))\n",
    "            labels.append(int(row['emotion']))\n",
    "        except (ValueError, IndexError) as e:\n",
    "            print(f\"Row {idx} skipped due to error: {e} | Data: {row}\")\n",
    "            skipped_rows += 1\n",
    "            continue\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(f\"Loaded {len(images)} CK+ images with 7 classes (using 920)\")\n",
    "    print(f\"Skipped {skipped_rows} rows due to errors.\")\n",
    "    return images, labels\n",
    "\n",
    "# Load KMU-FED dataset\n",
    "def load_kmu_fed(folder_path):\n",
    "    images, labels = [], []\n",
    "    emotion_map = {\n",
    "        'AN': 0,  # Anger\n",
    "        'DI': 1,  # Disgust\n",
    "        'FE': 2,  # Fear\n",
    "        'HA': 3,  # Happiness\n",
    "        'SA': 4,  # Sadness\n",
    "        'SU': 5   # Surprise\n",
    "    }\n",
    "    \n",
    "    extensions = ('*.jpg', '*.jpeg', '*.png')\n",
    "    img_files = []\n",
    "    for ext in extensions:\n",
    "        img_files.extend(glob(os.path.join(folder_path, ext)))\n",
    "    \n",
    "    if not img_files:\n",
    "        print(f\"No image files found in {folder_path}. Check dataset structure.\")\n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "    print(f\"Found {len(img_files)} images.\")\n",
    "    for img_path in img_files:\n",
    "        filename = os.path.basename(img_path)\n",
    "        emotion_code = filename.split('_')[1]\n",
    "        if emotion_code in emotion_map:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                images.append(preprocess_image(img))\n",
    "                labels.append(emotion_map[emotion_code])\n",
    "        else:\n",
    "            print(f\"Unknown emotion code {emotion_code} in {filename}\")\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(f\"Loaded {len(images)} KMU-FED images with 6 classes (expected 1106)\")\n",
    "    if len(images) < 1106:\n",
    "        print(\"Warning: Missing images. Dataset may be incomplete or partially downloaded.\")\n",
    "    return images, labels\n",
    "\n",
    "# Load datasets\n",
    "ck_path = \"/Users/adicadi/.cache/kagglehub/datasets/davilsena/ckdataset/versions/2/ckextended.csv\"\n",
    "kmu_path = \"/Users/adicadi/.cache/kagglehub/datasets/anandpanajkar/kmu-fed/versions/1\"\n",
    "\n",
    "ck_images, ck_labels = load_ckplus_from_csv(ck_path)\n",
    "kmu_images, kmu_labels = load_kmu_fed(kmu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7194179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Hybrid Channel Attention\n",
    "def hybrid_channel_attention(input_tensor, reduction_ratio=16):\n",
    "    channels = input_tensor.shape[-1]\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    x = tf.keras.layers.Dense(channels // reduction_ratio, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(channels, activation='sigmoid')(x)\n",
    "    x = tf.keras.layers.Multiply()([input_tensor, x])\n",
    "    return x\n",
    "\n",
    "# Custom Coordinate Space Attention Layer\n",
    "class CoordinateSpaceAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CoordinateSpaceAttention, self).__init__(**kwargs)\n",
    "        self.conv1d_x = tf.keras.layers.Conv1D(1, kernel_size=1, padding='same')\n",
    "        self.conv1d_y = tf.keras.layers.Conv1D(1, kernel_size=1, padding='same')\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        batch_size, height, width, channels = input_tensor.shape\n",
    "        \n",
    "        # Pool along width to get height-wise attention\n",
    "        x = tf.keras.layers.AveragePooling2D(pool_size=(1, width))(input_tensor)\n",
    "        x = tf.squeeze(x, axis=2)  # Shape: (batch_size, height, channels)\n",
    "        x = self.conv1d_x(x)  # Shape: (batch_size, height, 1)\n",
    "        x = self.sigmoid(x)  # Shape: (batch_size, height, 1)\n",
    "        x = tf.expand_dims(x, axis=2)  # Shape: (batch_size, height, 1, 1)\n",
    "        x = tf.tile(x, [1, 1, width, 1])  # Expand to match width\n",
    "        \n",
    "        # Pool along height to get width-wise attention\n",
    "        y = tf.keras.layers.AveragePooling2D(pool_size=(height, 1))(input_tensor)\n",
    "        y = tf.squeeze(y, axis=1)  # Shape: (batch_size, width, channels)\n",
    "        y = self.conv1d_y(y)  # Shape: (batch_size, width, 1)\n",
    "        y = self.sigmoid(y)  # Shape: (batch_size, width, 1)\n",
    "        y = tf.expand_dims(y, axis=1)  # Shape: (batch_size, 1, width, 1)\n",
    "        y = tf.tile(y, [1, height, 1, 1])  # Expand to match height\n",
    "        \n",
    "        # Combine and apply attention\n",
    "        attention = x * y  # Element-wise multiplication\n",
    "        attention = tf.reduce_mean(attention, axis=-1, keepdims=True)  # Combine into a single attention map\n",
    "        attention = self.sigmoid(attention)  # Normalize to [0, 1]\n",
    "        \n",
    "        return tf.keras.layers.Multiply()([input_tensor, attention])\n",
    "\n",
    "# Depthwise Attention Convolution (DAC) Block\n",
    "def dac_block(input_tensor, filters, kernel_size=3):\n",
    "    x = tf.keras.layers.SeparableConv2D(filters, kernel_size, padding='same')(input_tensor)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = hybrid_channel_attention(x)\n",
    "    x = CoordinateSpaceAttention()(x)\n",
    "    return x\n",
    "\n",
    "# DALDL Model\n",
    "def build_daldl(num_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=(227, 227, 1))\n",
    "    x = tf.keras.layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.GroupNormalization(groups=8)(x)\n",
    "    \n",
    "    # Residual blocks with DAC\n",
    "    for _ in range(3):\n",
    "        shortcut = x\n",
    "        x = dac_block(x, 64)\n",
    "        x = tf.keras.layers.Add()([shortcut, x])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "# Build models\n",
    "daldl_ck = build_daldl(num_classes=7)\n",
    "daldl_kmu = build_daldl(num_classes=6)\n",
    "\n",
    "# Compile models\n",
    "daldl_ck.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, weight_decay=0.0005),\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "daldl_kmu.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, weight_decay=0.0005),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1987bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n",
      "Fold 1/5 for CK+\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 233, 233, 1)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(None, 227, 227, 1), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m daldl_ck \u001b[38;5;241m=\u001b[39m build_model(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m     84\u001b[0m daldl_kmu \u001b[38;5;241m=\u001b[39m build_model(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaldl_ck\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mck_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mck_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCK+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m train_and_evaluate(daldl_kmu, kmu_images, kmu_labels, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKMU-FED\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 65\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, images, labels, num_classes, dataset_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[1;32m     60\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     61\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m),\n\u001b[1;32m     62\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m ]\n\u001b[0;32m---> 65\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_images)\n\u001b[1;32m     75\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(val_preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 233, 233, 1)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(None, 227, 227, 1), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "# Single cell for training and evaluation with recommended changes\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Define model with pre-trained ResNet50\n",
    "def build_model(num_classes):\n",
    "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(227, 227, 3))\n",
    "    base_model.trainable = False\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Custom augmentation function\n",
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    scale = tf.random.uniform([], 0.9, 1.1, dtype=tf.float32)\n",
    "    new_height = tf.cast(227 * scale, tf.int32)\n",
    "    new_width = tf.cast(227 * scale, tf.int32)\n",
    "    image = tf.image.resize(image, [new_height, new_width])\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 227, 227)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    return image, label\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model, images, labels, num_classes, dataset_name='ck+'):\n",
    "    k_folds = 5\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "    \n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    accuracies, f1_scores = [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(images)):\n",
    "        print(f'Fold {fold + 1}/{k_folds} for {dataset_name}')\n",
    "        train_images, val_images = images[train_idx], images[val_idx]\n",
    "        train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "        train_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        # Compile model with adaptive learning rate\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        ]\n",
    "\n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_dataset,\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        val_preds = model.predict(val_images)\n",
    "        val_preds = np.argmax(val_preds, axis=1)\n",
    "        accuracies.append(accuracy_score(val_labels, val_preds))\n",
    "        f1_scores.append(f1_score(val_labels, val_preds, average='weighted'))\n",
    "\n",
    "    print(f'{dataset_name} - Average Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}')\n",
    "    print(f'{dataset_name} - Average F1-Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}')\n",
    "\n",
    "# Build and train models\n",
    "daldl_ck = build_model(num_classes=7)\n",
    "daldl_kmu = build_model(num_classes=6)\n",
    "\n",
    "train_and_evaluate(daldl_ck, ck_images, ck_labels, num_classes=7, dataset_name='CK+')\n",
    "train_and_evaluate(daldl_kmu, kmu_images, kmu_labels, num_classes=6, dataset_name='KMU-FED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference speed test\n",
    "def measure_inference_time(model, images, num_runs=100):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_runs):\n",
    "        model.predict(images[:1], verbose=0)\n",
    "    avg_time = (time.time() - start_time) / num_runs * 1000\n",
    "    print(f'Average inference time: {avg_time:.2f} ms per image')\n",
    "\n",
    "measure_inference_time(daldl_ck, ck_images)\n",
    "measure_inference_time(daldl_kmu, kmu_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6e2e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to CK+ dataset files: /Users/adicadi/.cache/kagglehub/datasets/davilsena/ckdataset/versions/2\n",
      "Path to KMU-FED dataset files: /Users/adicadi/.cache/kagglehub/datasets/anandpanajkar/kmu-fed/versions/1\n",
      "CK+ directory contents: ['ckextended.csv']\n",
      "KMU-FED directory contents: ['12_AN_gu_185.jpg', '04_FE_s03_079.jpg', '11_DI_ej_111.jpg', '02_SU_s01_037.jpg', '02_SU_s01_023.jpg', '11_DI_ej_105.jpg', '05_SU_uj_076.jpg', '01_DI_mr_012.jpg', '03_FE_s02_043.jpg', '01_DI_mr_006.jpg', '03_FE_s02_057.jpg', '05_SU_uj_062.jpg', '05_HA_uj_086.jpg', '04_SU_s03_069.jpg', '11_SA_ej_147.jpg', '02_FE_s01_027.jpg', '06_SA_dy_089.jpg', '02_FE_s01_033.jpg', '03_SU_s02_053.jpg', '06_SA_dy_076.jpg', '03_SU_s02_047.jpg', '08_SU_nh_095.jpg', '05_HA_uj_079.jpg', '07_AN_sw_098.jpg', '08_SU_nh_081.jpg', '07_SA_sw_090.jpg', '07_SA_sw_084.jpg', '05_DI_uj_045.jpg', '01_SU_mr_009.jpg', '12_DI_gu_124.jpg', '02_HA_s01_023.jpg', '12_DI_gu_130.jpg', '11_AN_ej_167.jpg', '11_FE_ej_188.jpg', '11_SU_ej_136.jpg', '12_SA_gu_166.jpg', '04_HA_s03_069.jpg', '10_SU_ko_114.jpg', '01_HA_mr_006.jpg', '08_HA_nh_139.jpg', '01_HA_mr_012.jpg', '04_HA_s03_055.jpg', '10_SU_ko_128.jpg', '10_AN_ko_145.jpg', '10_FE_ko_169.jpg', '03_HA_s02_047.jpg', '08_DI_nh_071.jpg', '10_FE_ko_168.jpg', '03_HA_s02_046.jpg', '10_AN_ko_144.jpg', '10_AN_ko_150.jpg', '04_HA_s03_054.jpg', '10_SU_ko_129.jpg', '01_HA_mr_013.jpg', '08_HA_nh_138.jpg', '04_HA_s03_068.jpg', '12_SA_gu_167.jpg', '01_HA_mr_007.jpg', '10_SU_ko_115.jpg', '11_FE_ej_189.jpg', '11_SU_ej_137.jpg', '06_AN_dy_080.jpg', '11_AN_ej_166.jpg', '02_HA_s01_022.jpg', '12_DI_gu_125.jpg', '01_SU_mr_008.jpg', '05_DI_uj_044.jpg', '07_SA_sw_085.jpg', '10_DI_ko_091.jpg', '01_SU_mr_020.jpg', '05_DI_uj_050.jpg', '07_AN_sw_099.jpg', '08_SU_nh_094.jpg', '05_HA_uj_078.jpg', '03_SU_s02_046.jpg', '03_SU_s02_052.jpg', '06_SA_dy_077.jpg', '02_FE_s01_032.jpg', '02_FE_s01_026.jpg', '06_SA_dy_088.jpg', '04_SU_s03_068.jpg', '11_SA_ej_146.jpg', '05_HA_uj_087.jpg', '03_FE_s02_056.jpg', '01_DI_mr_007.jpg', '05_SU_uj_063.jpg', '05_SU_uj_077.jpg', '03_FE_s02_042.jpg', '01_DI_mr_013.jpg', '02_SU_s01_022.jpg', '11_DI_ej_104.jpg', '11_DI_ej_110.jpg', '02_SU_s01_036.jpg', '12_AN_gu_190.jpg', '04_FE_s03_078.jpg', '12_AN_gu_184.jpg', '11_FE_ej_200.jpg', '12_AN_gu_186.jpg', '11_DI_ej_106.jpg', '02_SU_s01_034.jpg', '11_DI_ej_112.jpg', '05_SU_uj_061.jpg', '01_DI_mr_005.jpg', '03_FE_s02_054.jpg', '04_SA_s03_049.jpg', '01_DI_mr_011.jpg', '05_SU_uj_075.jpg', '12_AN_gu_179.jpg', '11_SA_ej_144.jpg', '05_HA_uj_085.jpg', '11_SA_ej_150.jpg', '02_FE_s01_030.jpg', '02_FE_s01_024.jpg', '03_SU_s02_044.jpg', '06_SA_dy_075.jpg', '03_SU_s02_050.jpg', '08_SU_nh_082.jpg', '06_FE_dy_119.jpg', '08_SU_nh_096.jpg', '10_DI_ko_093.jpg', '05_DI_uj_046.jpg', '07_SA_sw_087.jpg', '06_AN_dy_069.jpg', '12_DI_gu_127.jpg', '11_AN_ej_164.jpg', '11_AN_ej_170.jpg', '11_AN_ej_158.jpg', '08_FE_nh_148.jpg', '07_SA_sw_078.jpg', '07_FE_sw_128.jpg', '11_SU_ej_135.jpg', '01_HA_mr_011.jpg', '09_FE_sj_160.jpg', '10_SU_ko_117.jpg', '01_HA_mr_005.jpg', '12_SA_gu_165.jpg', '10_AN_ko_146.jpg', '04_HA_s03_056.jpg', '12_SA_gu_159.jpg', '03_HA_s02_050.jpg', '03_HA_s02_044.jpg', '09_SU_sj_109.jpg', '08_DI_nh_072.jpg', '08_DI_nh_073.jpg', '03_HA_s02_045.jpg', '09_SU_sj_108.jpg', '12_SA_gu_158.jpg', '04_HA_s03_057.jpg', '10_AN_ko_147.jpg', '10_FE_ko_180.jpg', '01_HA_mr_004.jpg', '10_SU_ko_116.jpg', '12_SA_gu_164.jpg', '12_SA_gu_170.jpg', '01_HA_mr_010.jpg', '11_SU_ej_134.jpg', '11_AN_ej_159.jpg', '07_FE_sw_129.jpg', '07_SA_sw_079.jpg', '08_FE_nh_149.jpg', '11_AN_ej_165.jpg', '06_AN_dy_068.jpg', '02_HA_s01_021.jpg', '12_DI_gu_126.jpg', '10_DI_ko_092.jpg', '07_SA_sw_086.jpg', '05_DI_uj_047.jpg', '06_FE_dy_118.jpg', '08_SU_nh_097.jpg', '08_SU_nh_083.jpg', '06_SA_dy_074.jpg', '03_SU_s02_051.jpg', '03_SU_s02_045.jpg', '02_FE_s01_025.jpg', '02_FE_s01_031.jpg', '05_HA_uj_084.jpg', '11_SA_ej_145.jpg', '05_HA_uj_090.jpg', '12_AN_gu_178.jpg', '03_FE_s02_041.jpg', '01_DI_mr_010.jpg', '05_SU_uj_074.jpg', '04_SA_s03_048.jpg', '03_FE_s02_055.jpg', '01_DI_mr_004.jpg', '02_SU_s01_035.jpg', '11_DI_ej_113.jpg', '11_DI_ej_107.jpg', '02_SU_s01_021.jpg', '12_AN_gu_187.jpg', '02_SU_s01_025.jpg', '11_DI_ej_103.jpg', '11_DI_ej_117.jpg', '02_SU_s01_031.jpg', '12_AN_gu_183.jpg', '04_FE_s03_080.jpg', '03_FE_s02_051.jpg', '05_SU_uj_064.jpg', '05_SU_uj_070.jpg', '03_FE_s02_045.jpg', '01_DI_mr_014.jpg', '02_FE_s01_035.jpg', '02_FE_s01_021.jpg', '11_SA_ej_141.jpg', '05_HA_uj_080.jpg', '06_FE_dy_108.jpg', '08_SU_nh_087.jpg', '08_SU_nh_093.jpg', '03_SU_s02_041.jpg', '03_SU_s02_055.jpg', '06_FE_dy_120.jpg', '06_AN_dy_078.jpg', '12_DI_gu_122.jpg', '02_HA_s01_025.jpg', '05_DI_uj_043.jpg', '07_SA_sw_082.jpg', '10_DI_ko_096.jpg', '07_FE_sw_139.jpg', '11_AN_ej_161.jpg', '09_FE_sj_159.jpg', '10_AN_ko_143.jpg', '04_HA_s03_053.jpg', '01_HA_mr_014.jpg', '12_SA_gu_160.jpg', '08_DI_nh_088.jpg', '10_SU_ko_112.jpg', '08_DI_nh_077.jpg', '03_HA_s02_041.jpg', '03_HA_s02_040.jpg', '08_DI_nh_076.jpg', '12_SA_gu_161.jpg', '10_SU_ko_113.jpg', '01_HA_mr_001.jpg', '08_DI_nh_089.jpg', '01_HA_mr_015.jpg', '04_HA_s03_052.jpg', '09_FE_sj_158.jpg', '10_AN_ko_142.jpg', '11_AN_ej_160.jpg', '11_SU_ej_131.jpg', '07_FE_sw_138.jpg', '07_AN_sw_100.jpg', '07_SA_sw_083.jpg', '05_DI_uj_042.jpg', '10_DI_ko_097.jpg', '02_HA_s01_024.jpg', '12_DI_gu_123.jpg', '06_AN_dy_079.jpg', '02_HA_s01_030.jpg', '03_SU_s02_054.jpg', '06_SA_dy_071.jpg', '08_SU_nh_092.jpg', '06_FE_dy_109.jpg', '08_SU_nh_086.jpg', '05_HA_uj_081.jpg', '11_SA_ej_140.jpg', '02_FE_s01_034.jpg', '05_SU_uj_071.jpg', '01_DI_mr_015.jpg', '03_FE_s02_044.jpg', '01_DI_mr_001.jpg', '03_FE_s02_050.jpg', '05_SU_uj_065.jpg', '12_AN_gu_182.jpg', '11_DI_ej_116.jpg', '02_SU_s01_030.jpg', '02_SU_s01_024.jpg', '11_DI_ej_102.jpg', '02_SU_s01_032.jpg', '11_DI_ej_114.jpg', '02_SU_s01_026.jpg', '12_AN_gu_180.jpg', '04_FE_s03_068.jpg', '03_FE_s02_046.jpg', '01_DI_mr_017.jpg', '05_SU_uj_073.jpg', '05_SU_uj_067.jpg', '03_FE_s02_052.jpg', '01_DI_mr_003.jpg', '02_FE_s01_022.jpg', '02_FE_s01_036.jpg', '05_HA_uj_083.jpg', '11_SA_ej_142.jpg', '07_AN_sw_089.jpg', '08_SU_nh_090.jpg', '08_SU_nh_084.jpg', '06_SA_dy_073.jpg', '03_SU_s02_056.jpg', '03_SU_s02_042.jpg', '12_DI_gu_121.jpg', '02_HA_s01_026.jpg', '01_SU_mr_018.jpg', '10_DI_ko_095.jpg', '07_SA_sw_081.jpg', '05_DI_uj_040.jpg', '02_AN_s01_028.jpg', '11_SU_ej_133.jpg', '11_FE_ej_199.jpg', '11_AN_ej_162.jpg', '01_HA_mr_003.jpg', '10_SU_ko_111.jpg', '12_SA_gu_163.jpg', '01_HA_mr_017.jpg', '08_DI_nh_074.jpg', '03_HA_s02_042.jpg', '10_FE_ko_178.jpg', '10_FE_ko_179.jpg', '03_HA_s02_043.jpg', '08_DI_nh_075.jpg', '01_HA_mr_016.jpg', '01_HA_mr_002.jpg', '12_SA_gu_162.jpg', '10_AN_ko_141.jpg', '04_HA_s03_051.jpg', '11_AN_ej_163.jpg', '11_FE_ej_198.jpg', '11_SU_ej_132.jpg', '02_AN_s01_029.jpg', '10_DI_ko_094.jpg', '05_DI_uj_041.jpg', '07_SA_sw_080.jpg', '01_SU_mr_019.jpg', '02_HA_s01_027.jpg', '03_SU_s02_043.jpg', '06_SA_dy_072.jpg', '03_SU_s02_057.jpg', '08_SU_nh_085.jpg', '07_AN_sw_088.jpg', '08_SU_nh_091.jpg', '11_SA_ej_143.jpg', '05_HA_uj_082.jpg', '02_FE_s01_037.jpg', '02_FE_s01_023.jpg', '05_SU_uj_066.jpg', '01_DI_mr_002.jpg', '03_FE_s02_053.jpg', '01_DI_mr_016.jpg', '03_FE_s02_047.jpg', '05_SU_uj_072.jpg', '04_FE_s03_069.jpg', '12_AN_gu_181.jpg', '11_DI_ej_101.jpg', '02_SU_s01_027.jpg', '02_SU_s01_033.jpg', '11_DI_ej_115.jpg', '09_SA_sj_118.jpg', '02_SU_s01_040.jpg', '05_FE_uj_097.jpg', '06_DI_dy_057.jpg', '05_AN_uj_050.jpg', '05_FE_uj_083.jpg', '05_AN_uj_044.jpg', '12_HA_gu_190.jpg', '12_HA_gu_184.jpg', '07_SU_sw_096.jpg', '07_SU_sw_082.jpg', '05_DI_uj_032.jpg', '08_AN_nh_104.jpg', '08_SA_nh_093.jpg', '08_AN_nh_110.jpg', '01_AN_mr_013.jpg', '10_HA_ko_178.jpg', '01_AN_mr_007.jpg', '10_HA_ko_187.jpg', '01_FE_mr_017.jpg', '09_HA_sj_166.jpg', '01_FE_mr_003.jpg', '11_SU_ej_141.jpg', '05_SA_uj_058.jpg', '05_SA_uj_070.jpg', '07_HA_sw_112.jpg', '05_SA_uj_064.jpg', '06_HA_dy_094.jpg', '09_AN_sj_138.jpg', '09_AN_sj_139.jpg', '06_HA_dy_095.jpg', '03_HA_s02_031.jpg', '05_SA_uj_065.jpg', '07_HA_sw_113.jpg', '05_SA_uj_059.jpg', '11_SU_ej_140.jpg', '01_FE_mr_002.jpg', '09_HA_sj_167.jpg', '01_FE_mr_016.jpg', '10_HA_ko_186.jpg', '01_AN_mr_006.jpg', '01_AN_mr_012.jpg', '10_HA_ko_179.jpg', '08_AN_nh_111.jpg', '08_SA_nh_092.jpg', '08_AN_nh_105.jpg', '05_DI_uj_033.jpg', '07_SU_sw_083.jpg', '07_SU_sw_097.jpg', '12_HA_gu_185.jpg', '11_SA_ej_131.jpg', '05_AN_uj_045.jpg', '05_FE_uj_082.jpg', '05_AN_uj_051.jpg', '06_DI_dy_056.jpg', '05_FE_uj_096.jpg', '09_SA_sj_119.jpg', '06_HA_dy_108.jpg', '03_SA_s02_038.jpg', '06_DI_dy_068.jpg', '05_AN_uj_047.jpg', '06_DI_dy_054.jpg', '05_FE_uj_094.jpg', '05_AN_uj_053.jpg', '11_SA_ej_133.jpg', '12_HA_gu_187.jpg', '01_SA_mr_018.jpg', '12_HA_gu_178.jpg', '07_SU_sw_081.jpg', '07_SU_sw_095.jpg', '08_AN_nh_113.jpg', '08_AN_nh_107.jpg', '05_DI_uj_031.jpg', '01_AN_mr_004.jpg', '01_AN_mr_010.jpg', '10_HA_ko_190.jpg', '06_SU_dy_098.jpg', '10_HA_ko_184.jpg', '09_HA_sj_159.jpg', '11_SU_ej_142.jpg', '09_HA_sj_165.jpg', '01_FE_mr_014.jpg', '05_SA_uj_067.jpg', '07_HA_sw_111.jpg', '03_HA_s02_033.jpg', '06_HA_dy_097.jpg', '06_HA_dy_096.jpg', '03_HA_s02_032.jpg', '05_SA_uj_066.jpg', '01_FE_mr_015.jpg', '09_HA_sj_164.jpg', '11_SU_ej_143.jpg', '01_FE_mr_001.jpg', '09_HA_sj_170.jpg', '10_HA_ko_185.jpg', '09_HA_sj_158.jpg', '06_SU_dy_099.jpg', '01_AN_mr_011.jpg', '01_AN_mr_005.jpg', '08_SA_nh_091.jpg', '08_AN_nh_106.jpg', '08_AN_nh_112.jpg', '07_SU_sw_094.jpg', '01_SA_mr_019.jpg', '12_HA_gu_179.jpg', '12_HA_gu_186.jpg', '11_SA_ej_132.jpg', '05_AN_uj_052.jpg', '05_FE_uj_095.jpg', '06_DI_dy_055.jpg', '05_AN_uj_046.jpg', '05_FE_uj_081.jpg', '06_DI_dy_069.jpg', '03_SA_s02_039.jpg', '06_HA_dy_109.jpg', '03_SA_s02_029.jpg', '05_FE_uj_085.jpg', '05_AN_uj_042.jpg', '06_DI_dy_051.jpg', '05_FE_uj_091.jpg', '05_AN_uj_056.jpg', '12_HA_gu_182.jpg', '11_SA_ej_136.jpg', '07_SU_sw_084.jpg', '07_SU_sw_090.jpg', '01_SA_mr_009.jpg', '01_AN_mr_001.jpg', '01_AN_mr_015.jpg', '08_AN_nh_116.jpg', '08_AN_nh_102.jpg', '05_DI_uj_034.jpg', '08_SA_nh_095.jpg', '01_FE_mr_005.jpg', '11_SU_ej_147.jpg', '09_HA_sj_160.jpg', '01_FE_mr_011.jpg', '06_SU_dy_089.jpg', '10_HA_ko_181.jpg', '05_SA_uj_062.jpg', '07_HA_sw_114.jpg', '03_AN_s02_038.jpg', '08_HA_nh_148.jpg', '07_HA_sw_128.jpg', '06_HA_dy_092.jpg', '03_HA_s02_036.jpg', '03_HA_s02_037.jpg', '06_HA_dy_093.jpg', '07_HA_sw_129.jpg', '08_HA_nh_149.jpg', '03_AN_s02_039.jpg', '07_HA_sw_115.jpg', '05_SA_uj_063.jpg', '10_HA_ko_180.jpg', '06_SU_dy_088.jpg', '01_FE_mr_010.jpg', '09_HA_sj_161.jpg', '11_SU_ej_146.jpg', '01_FE_mr_004.jpg', '08_SA_nh_094.jpg', '05_DI_uj_035.jpg', '08_AN_nh_103.jpg', '08_AN_nh_117.jpg', '01_AN_mr_014.jpg', '01_SA_mr_008.jpg', '07_SU_sw_091.jpg', '07_SU_sw_085.jpg', '01_SA_mr_020.jpg', '11_SA_ej_137.jpg', '12_HA_gu_183.jpg', '05_AN_uj_057.jpg', '05_FE_uj_090.jpg', '05_AN_uj_043.jpg', '05_FE_uj_084.jpg', '03_SA_s02_028.jpg', '05_FE_uj_092.jpg', '06_DI_dy_052.jpg', '05_AN_uj_055.jpg', '05_FE_uj_086.jpg', '05_AN_uj_041.jpg', '12_HA_gu_181.jpg', '11_SA_ej_135.jpg', '07_SU_sw_093.jpg', '08_SA_nh_109.jpg', '07_SU_sw_087.jpg', '01_AN_mr_016.jpg', '01_AN_mr_002.jpg', '05_DI_uj_037.jpg', '08_AN_nh_101.jpg', '08_SA_nh_096.jpg', '08_AN_nh_115.jpg', '11_SU_ej_150.jpg', '01_FE_mr_012.jpg', '09_HA_sj_163.jpg', '01_FE_mr_006.jpg', '11_SU_ej_144.jpg', '10_HA_ko_182.jpg', '07_HA_sw_117.jpg', '05_SA_uj_061.jpg', '09_AN_sj_129.jpg', '06_HA_dy_091.jpg', '03_HA_s02_035.jpg', '03_HA_s02_034.jpg', '09_AN_sj_128.jpg', '05_SA_uj_060.jpg', '07_HA_sw_116.jpg', '10_HA_ko_183.jpg', '11_SU_ej_145.jpg', '01_FE_mr_007.jpg', '09_HA_sj_162.jpg', '01_FE_mr_013.jpg', '08_AN_nh_114.jpg', '08_SA_nh_097.jpg', '05_DI_uj_036.jpg', '01_AN_mr_003.jpg', '01_AN_mr_017.jpg', '08_SA_nh_108.jpg', '07_SU_sw_086.jpg', '07_SU_sw_092.jpg', '11_SA_ej_134.jpg', '12_HA_gu_180.jpg', '06_SU_dy_100.jpg', '02_FE_s01_040.jpg', '05_FE_uj_087.jpg', '05_AN_uj_054.jpg', '06_DI_dy_053.jpg', '05_FE_uj_093.jpg', '09_SA_sj_111.jpg', '03_SA_s02_032.jpg', '03_SA_s02_026.jpg', '06_HA_dy_102.jpg', '05_AN_uj_059.jpg', '06_DI_dy_062.jpg', '11_SA_ej_139.jpg', '08_SA_nh_105.jpg', '01_SA_mr_012.jpg', '12_HA_gu_172.jpg', '01_SA_mr_006.jpg', '10_HA_ko_171.jpg', '08_AN_nh_119.jpg', '07_SU_sw_100.jpg', '11_SU_ej_148.jpg', '06_SU_dy_092.jpg', '06_SU_dy_086.jpg', '09_HA_sj_153.jpg', '05_SA_uj_051.jpg', '03_AN_s02_037.jpg', '08_HA_nh_147.jpg', '07_HA_sw_127.jpg', '09_AN_sj_131.jpg', '1_AN_mr_003.jpg', '09_AN_sj_125.jpg', '03_HA_s02_039.jpg', '03_HA_s02_038.jpg', '1_AN_mr_002.jpg', '09_AN_sj_124.jpg', '09_AN_sj_130.jpg', '07_HA_sw_126.jpg', '08_HA_nh_146.jpg', '05_FE_uj_100.jpg', '03_AN_s02_036.jpg', '06_SU_dy_087.jpg', '09_HA_sj_152.jpg', '06_SU_dy_093.jpg', '07_FE_sw_140.jpg', '11_SU_ej_149.jpg', '08_AN_nh_118.jpg', '01_SA_mr_007.jpg', '01_SA_mr_013.jpg', '12_HA_gu_173.jpg', '08_SA_nh_110.jpg', '08_SA_nh_104.jpg', '11_SA_ej_138.jpg', '06_DI_dy_063.jpg', '05_AN_uj_058.jpg', '06_HA_dy_103.jpg', '03_SA_s02_027.jpg', '09_SA_sj_110.jpg', '03_SA_s02_033.jpg', '03_SA_s02_025.jpg', '03_SA_s02_031.jpg', '09_SA_sj_112.jpg', '06_HA_dy_101.jpg', '05_FE_uj_089.jpg', '06_DI_dy_061.jpg', '07_SU_sw_088.jpg', '08_SA_nh_106.jpg', '01_SA_mr_005.jpg', '12_HA_gu_171.jpg', '01_SA_mr_011.jpg', '01_AN_mr_019.jpg', '10_HA_ko_172.jpg', '05_DI_uj_038.jpg', '08_SA_nh_099.jpg', '01_FE_mr_009.jpg', '06_SU_dy_085.jpg', '06_SU_dy_091.jpg', '07_HA_sw_118.jpg', '08_HA_nh_144.jpg', '07_HA_sw_124.jpg', '03_AN_s02_034.jpg', '08_HA_nh_150.jpg', '07_HA_sw_130.jpg', '05_SA_uj_052.jpg', '09_AN_sj_126.jpg', '09_AN_sj_132.jpg', '09_AN_sj_133.jpg', '09_AN_sj_127.jpg', '1_AN_mr_001.jpg', '03_AN_s02_035.jpg', '05_SA_uj_053.jpg', '07_HA_sw_125.jpg', '08_HA_nh_145.jpg', '07_HA_sw_119.jpg', '06_SU_dy_090.jpg', '01_FE_mr_020.jpg', '09_HA_sj_151.jpg', '06_SU_dy_084.jpg', '01_FE_mr_008.jpg', '08_SA_nh_098.jpg', '05_DI_uj_039.jpg', '01_AN_mr_018.jpg', '10_HA_ko_173.jpg', '01_SA_mr_010.jpg', '01_SA_mr_004.jpg', '07_SU_sw_089.jpg', '08_SA_nh_107.jpg', '06_DI_dy_060.jpg', '05_FE_uj_088.jpg', '06_HA_dy_100.jpg', '03_SA_s02_030.jpg', '09_SA_sj_113.jpg', '03_SA_s02_024.jpg', '06_HA_dy_104.jpg', '06_HA_dy_110.jpg', '09_SA_sj_117.jpg', '03_SA_s02_034.jpg', '06_DI_dy_064.jpg', '06_DI_dy_070.jpg', '05_FE_uj_098.jpg', '06_DI_dy_058.jpg', '01_SA_mr_014.jpg', '12_HA_gu_174.jpg', '07_SU_sw_099.jpg', '08_SA_nh_103.jpg', '01_AN_mr_020.jpg', '10_HA_ko_177.jpg', '01_AN_mr_008.jpg', '10_HA_ko_188.jpg', '09_HA_sj_155.jpg', '06_SU_dy_094.jpg', '01_FE_mr_018.jpg', '09_HA_sj_169.jpg', '08_HA_nh_141.jpg', '07_HA_sw_121.jpg', '05_SA_uj_057.jpg', '03_AN_s02_031.jpg', '1_AN_mr_005.jpg', '09_AN_sj_123.jpg', '09_AN_sj_137.jpg', '09_AN_sj_136.jpg', '1_AN_mr_004.jpg', '09_AN_sj_122.jpg', '05_SA_uj_056.jpg', '07_HA_sw_120.jpg', '08_HA_nh_140.jpg', '09_HA_sj_168.jpg', '01_FE_mr_019.jpg', '06_SU_dy_095.jpg', '10_HA_ko_189.jpg', '06_SU_dy_081.jpg', '09_HA_sj_154.jpg', '01_AN_mr_009.jpg', '10_HA_ko_176.jpg', '08_SA_nh_102.jpg', '07_SU_sw_098.jpg', '01_SA_mr_015.jpg', '12_HA_gu_175.jpg', '01_SA_mr_001.jpg', '06_DI_dy_059.jpg', '05_FE_uj_099.jpg', '06_DI_dy_065.jpg', '09_SA_sj_116.jpg', '03_SA_s02_035.jpg', '03_SA_s02_021.jpg', '06_HA_dy_105.jpg', '06_HA_dy_107.jpg', '03_SA_s02_037.jpg', '09_SA_sj_114.jpg', '03_SA_s02_023.jpg', '06_DI_dy_067.jpg', '05_AN_uj_060.jpg', '05_AN_uj_048.jpg', '12_HA_gu_188.jpg', '12_HA_gu_177.jpg', '01_SA_mr_017.jpg', '01_SA_mr_003.jpg', '08_SA_nh_100.jpg', '08_AN_nh_108.jpg', '08_AN_nh_120.jpg', '10_HA_ko_174.jpg', '06_SU_dy_097.jpg', '09_HA_sj_156.jpg', '06_SU_dy_083.jpg', '03_AN_s02_032.jpg', '05_SA_uj_054.jpg', '08_HA_nh_142.jpg', '07_HA_sw_122.jpg', '05_SA_uj_068.jpg', '06_HA_dy_098.jpg', '09_AN_sj_134.jpg', '1_AN_mr_006.jpg', '09_AN_sj_121.jpg', '09_AN_sj_135.jpg', '06_HA_dy_099.jpg', '05_SA_uj_069.jpg', '07_HA_sw_123.jpg', '08_HA_nh_143.jpg', '03_AN_s02_033.jpg', '05_SA_uj_055.jpg', '09_HA_sj_157.jpg', '06_SU_dy_082.jpg', '06_SU_dy_096.jpg', '10_HA_ko_175.jpg', '08_AN_nh_109.jpg', '08_SA_nh_101.jpg', '01_SA_mr_002.jpg', '12_HA_gu_176.jpg', '01_SA_mr_016.jpg', '12_HA_gu_189.jpg', '05_AN_uj_049.jpg', '06_DI_dy_066.jpg', '03_SA_s02_022.jpg', '03_SA_s02_036.jpg', '09_SA_sj_115.jpg', '06_HA_dy_106.jpg', '11_DI_ej_118.jpg', '05_SU_uj_080.jpg', '04_FE_s03_070.jpg', '04_FE_s03_064.jpg', '12_AN_gu_173.jpg', '04_SA_s03_043.jpg', '06_SA_dy_080.jpg', '08_SU_nh_088.jpg', '06_FE_dy_107.jpg', '07_AN_sw_091.jpg', '06_FE_dy_113.jpg', '07_AN_sw_085.jpg', '01_SU_mr_014.jpg', '06_AN_dy_077.jpg', '06_AN_dy_063.jpg', '10_DI_ko_099.jpg', '11_FE_ej_195.jpg', '11_AN_ej_152.jpg', '08_FE_nh_142.jpg', '02_AN_s01_030.jpg', '07_SA_sw_072.jpg', '07_FE_sw_122.jpg', '02_AN_s01_024.jpg', '07_FE_sw_136.jpg', '11_FE_ej_181.jpg', '09_FE_sj_156.jpg', '10_SU_ko_121.jpg', '12_SA_gu_153.jpg', '08_DI_nh_087.jpg', '04_HA_s03_060.jpg', '03_AN_s02_040.jpg', '08_DI_nh_078.jpg', '10_FE_ko_174.jpg', '09_SU_sj_103.jpg', '10_FE_ko_161.jpg', '09_SU_sj_102.jpg', '10_FE_ko_175.jpg', '08_DI_nh_079.jpg', '08_DI_nh_086.jpg', '04_HA_s03_061.jpg', '08_HA_nh_131.jpg', '10_SU_ko_120.jpg', '12_SA_gu_152.jpg', '09_FE_sj_157.jpg', '07_FE_sw_137.jpg', '02_AN_s01_025.jpg', '11_AN_ej_153.jpg', '11_FE_ej_194.jpg', '07_FE_sw_123.jpg', '07_SA_sw_073.jpg', '08_FE_nh_143.jpg', '10_DI_ko_098.jpg', '06_AN_dy_062.jpg', '01_SU_mr_001.jpg', '01_SU_mr_015.jpg', '06_AN_dy_076.jpg', '07_AN_sw_084.jpg', '06_FE_dy_112.jpg', '05_HA_uj_071.jpg', '08_SU_nh_089.jpg', '07_AN_sw_090.jpg', '06_FE_dy_106.jpg', '04_SU_s03_061.jpg', '06_SA_dy_081.jpg', '04_SA_s03_042.jpg', '12_AN_gu_172.jpg', '04_FE_s03_065.jpg', '04_FE_s03_071.jpg', '11_DI_ej_119.jpg', '02_SU_s01_029.jpg', '04_FE_s03_067.jpg', '04_FE_s03_073.jpg', '01_DI_mr_018.jpg', '03_FE_s02_049.jpg', '05_SU_uj_068.jpg', '06_SA_dy_083.jpg', '02_FE_s01_039.jpg', '04_SU_s03_063.jpg', '05_HA_uj_073.jpg', '06_FE_dy_110.jpg', '07_AN_sw_086.jpg', '06_FE_dy_104.jpg', '07_AN_sw_092.jpg', '03_SU_s02_059.jpg', '02_HA_s01_029.jpg', '01_SU_mr_003.jpg', '06_AN_dy_074.jpg', '01_SU_mr_017.jpg', '08_SU_nh_100.jpg', '11_FE_ej_182.jpg', '02_AN_s01_027.jpg', '07_FE_sw_135.jpg', '08_FE_nh_141.jpg', '07_SA_sw_071.jpg', '07_FE_sw_121.jpg', '11_FE_ej_196.jpg', '11_AN_ej_151.jpg', '10_SU_ko_122.jpg', '09_FE_sj_155.jpg', '04_HA_s03_063.jpg', '08_DI_nh_084.jpg', '08_DI_nh_090.jpg', '08_HA_nh_133.jpg', '01_HA_mr_018.jpg', '10_FE_ko_163.jpg', '10_FE_ko_177.jpg', '10_FE_ko_176.jpg', '10_FE_ko_162.jpg', '09_SU_sj_101.jpg', '01_HA_mr_019.jpg', '08_HA_nh_132.jpg', '04_HA_s03_062.jpg', '08_DI_nh_085.jpg', '09_FE_sj_154.jpg', '12_SA_gu_151.jpg', '10_SU_ko_123.jpg', '11_FE_ej_197.jpg', '11_FE_ej_183.jpg', '07_FE_sw_134.jpg', '02_AN_s01_026.jpg', '06_AN_dy_075.jpg', '01_SU_mr_016.jpg', '01_SU_mr_002.jpg', '02_HA_s01_028.jpg', '06_AN_dy_061.jpg', '03_SU_s02_058.jpg', '07_AN_sw_093.jpg', '06_FE_dy_105.jpg', '07_AN_sw_087.jpg', '06_FE_dy_111.jpg', '05_HA_uj_072.jpg', '04_SU_s03_062.jpg', '02_FE_s01_038.jpg', '06_SA_dy_082.jpg', '04_SA_s03_041.jpg', '05_SU_uj_069.jpg', '03_FE_s02_048.jpg', '01_DI_mr_019.jpg', '03_FE_s02_060.jpg', '12_AN_gu_171.jpg', '04_FE_s03_072.jpg', '04_FE_s03_066.jpg', '02_SU_s01_028.jpg', '04_FE_s03_062.jpg', '04_FE_s03_076.jpg', '02_SU_s01_038.jpg', '05_SU_uj_079.jpg', '04_SA_s03_045.jpg', '03_FE_s02_058.jpg', '01_DI_mr_009.jpg', '12_AN_gu_175.jpg', '05_HA_uj_089.jpg', '11_SA_ej_148.jpg', '04_SU_s03_066.jpg', '06_SA_dy_086.jpg', '02_FE_s01_028.jpg', '06_SA_dy_079.jpg', '03_SU_s02_048.jpg', '05_HA_uj_076.jpg', '06_FE_dy_115.jpg', '07_AN_sw_083.jpg', '10_DI_ko_100.jpg', '03_SU_s02_060.jpg', '06_FE_dy_101.jpg', '07_AN_sw_097.jpg', '06_AN_dy_065.jpg', '01_SU_mr_006.jpg', '01_SU_mr_012.jpg', '06_AN_dy_071.jpg', '11_AN_ej_168.jpg', '11_SU_ej_139.jpg', '02_AN_s01_022.jpg', '08_FE_nh_150.jpg', '07_FE_sw_130.jpg', '11_FE_ej_187.jpg', '11_FE_ej_193.jpg', '11_AN_ej_154.jpg', '08_FE_nh_144.jpg', '07_FE_sw_124.jpg', '07_SA_sw_074.jpg', '01_HA_mr_009.jpg', '08_DI_nh_081.jpg', '04_HA_s03_066.jpg', '12_SA_gu_169.jpg', '08_HA_nh_136.jpg', '10_SU_ko_127.jpg', '12_SA_gu_155.jpg', '03_HA_s02_048.jpg', '10_FE_ko_166.jpg', '09_SU_sj_105.jpg', '10_FE_ko_172.jpg', '09_AN_sj_140.jpg', '09_SU_sj_110.jpg', '10_FE_ko_173.jpg', '03_HA_s02_049.jpg', '09_SU_sj_104.jpg', '10_FE_ko_167.jpg', '09_FE_sj_151.jpg', '01_HA_mr_020.jpg', '10_SU_ko_126.jpg', '12_SA_gu_154.jpg', '08_HA_nh_137.jpg', '08_DI_nh_080.jpg', '01_HA_mr_008.jpg', '12_SA_gu_168.jpg', '04_HA_s03_067.jpg', '11_AN_ej_155.jpg', '11_FE_ej_192.jpg', '07_SA_sw_075.jpg', '07_FE_sw_125.jpg', '08_FE_nh_145.jpg', '07_FE_sw_131.jpg', '02_AN_s01_023.jpg', '11_SU_ej_138.jpg', '11_FE_ej_186.jpg', '11_AN_ej_169.jpg', '01_SU_mr_013.jpg', '06_AN_dy_070.jpg', '06_AN_dy_064.jpg', '01_SU_mr_007.jpg', '07_AN_sw_096.jpg', '07_AN_sw_082.jpg', '06_FE_dy_114.jpg', '05_HA_uj_077.jpg', '03_SU_s02_049.jpg', '06_SA_dy_078.jpg', '06_SA_dy_087.jpg', '02_FE_s01_029.jpg', '11_SA_ej_149.jpg', '04_SU_s03_067.jpg', '05_HA_uj_088.jpg', '01_DI_mr_020.jpg', '12_AN_gu_174.jpg', '01_DI_mr_008.jpg', '03_FE_s02_059.jpg', '04_SA_s03_044.jpg', '04_SA_s03_050.jpg', '05_SU_uj_078.jpg', '02_SU_s01_039.jpg', '04_FE_s03_077.jpg', '04_FE_s03_063.jpg', '04_FE_s03_075.jpg', '04_FE_s03_061.jpg', '12_AN_gu_189.jpg', '11_DI_ej_109.jpg', '03_SA_s02_040.jpg', '04_SA_s03_046.jpg', '12_AN_gu_176.jpg', '04_SU_s03_065.jpg', '06_SA_dy_085.jpg', '06_FE_dy_102.jpg', '07_AN_sw_094.jpg', '08_SU_nh_099.jpg', '05_HA_uj_075.jpg', '06_FE_dy_116.jpg', '05_DI_uj_049.jpg', '07_SA_sw_088.jpg', '06_AN_dy_072.jpg', '01_SU_mr_011.jpg', '12_DI_gu_128.jpg', '01_SU_mr_005.jpg', '06_AN_dy_066.jpg', '08_FE_nh_147.jpg', '07_FE_sw_127.jpg', '07_SA_sw_077.jpg', '11_FE_ej_190.jpg', '11_AN_ej_157.jpg', '11_FE_ej_184.jpg', '02_AN_s01_021.jpg', '07_FE_sw_133.jpg', '08_HA_nh_135.jpg', '04_HA_s03_065.jpg', '10_SU_ko_118.jpg', '08_DI_nh_082.jpg', '09_FE_sj_153.jpg', '10_SU_ko_130.jpg', '10_AN_ko_149.jpg', '12_SA_gu_156.jpg', '04_HA_s03_059.jpg', '10_SU_ko_124.jpg', '10_FE_ko_171.jpg', '10_FE_ko_165.jpg', '09_SU_sj_106.jpg', '09_SU_sj_107.jpg', '10_FE_ko_164.jpg', '10_FE_ko_170.jpg', '04_HA_s03_058.jpg', '12_SA_gu_157.jpg', '10_SU_ko_125.jpg', '09_FE_sj_152.jpg', '10_AN_ko_148.jpg', '04_HA_s03_064.jpg', '08_DI_nh_083.jpg', '10_SU_ko_119.jpg', '08_HA_nh_134.jpg', '04_HA_s03_070.jpg', '11_FE_ej_185.jpg', '07_FE_sw_132.jpg', '07_SA_sw_076.jpg', '07_FE_sw_126.jpg', '08_FE_nh_146.jpg', '11_AN_ej_156.jpg', '11_FE_ej_191.jpg', '01_SU_mr_004.jpg', '12_DI_gu_129.jpg', '06_AN_dy_067.jpg', '06_AN_dy_073.jpg', '01_SU_mr_010.jpg', '07_SA_sw_089.jpg', '05_DI_uj_048.jpg', '08_SU_nh_098.jpg', '07_AN_sw_081.jpg', '06_FE_dy_117.jpg', '05_HA_uj_074.jpg', '07_AN_sw_095.jpg', '06_FE_dy_103.jpg', '06_SA_dy_084.jpg', '06_SA_dy_090.jpg', '04_SU_s03_070.jpg', '04_SU_s03_064.jpg', '12_AN_gu_177.jpg', '04_SA_s03_047.jpg', '11_DI_ej_108.jpg', '11_DI_ej_120.jpg', '12_AN_gu_188.jpg', '04_FE_s03_074.jpg']\n",
      "CSV columns in /Users/adicadi/.cache/kagglehub/datasets/davilsena/ckdataset/versions/2/ckextended.csv: ['emotion', 'pixels', 'Usage']\n",
      "Loaded 920 images from /Users/adicadi/.cache/kagglehub/datasets/davilsena/ckdataset/versions/2\n",
      "Loaded 1106 images from /Users/adicadi/.cache/kagglehub/datasets/anandpanajkar/kmu-fed/versions/1 with shape (227, 227, 3)\n",
      "Fold 1/5 for CK+\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:58:57.928346: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [14528,227,227,1] vs. [64,227,227,16]\n",
      "\t [[{{function_node __inference_one_step_on_data_130891}}{{node functional_8_1/csa_layer_9_1/mul}}]]\n",
      "2025-06-14 19:58:57.929069: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 8973604330050715878\n",
      "2025-06-14 19:58:57.929178: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [14528,227,227,1] vs. [64,227,227,16]\n",
      "\t [[{{function_node __inference_one_step_on_data_130891}}{{node functional_8_1/csa_layer_9_1/mul}}]]\n",
      "\t [[StatefulPartitionedCall/functional_8_1/dense_37_1/Softmax/_336]]\n",
      "2025-06-14 19:58:57.929340: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 5700340834337074411\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_8_1/csa_layer_9_1/mul defined at (most recent call last):\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 190, in <module>\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 172, in train_and_evaluate\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 116, in call\n\nDetected at node functional_8_1/csa_layer_9_1/mul defined at (most recent call last):\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 190, in <module>\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 172, in train_and_evaluate\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 116, in call\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Incompatible shapes: [14528,227,227,1] vs. [64,227,227,16]\n\t [[{{node functional_8_1/csa_layer_9_1/mul}}]]\n\t [[StatefulPartitionedCall/functional_8_1/dense_37_1/Softmax/_336]]\n  (1) INVALID_ARGUMENT:  Incompatible shapes: [14528,227,227,1] vs. [64,227,227,16]\n\t [[{{node functional_8_1/csa_layer_9_1/mul}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_131258]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 190\u001b[0m\n\u001b[1;32m    187\u001b[0m daldl_ck \u001b[38;5;241m=\u001b[39m build_daldl_model(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)  \u001b[38;5;66;03m# 7 classes for CK+\u001b[39;00m\n\u001b[1;32m    188\u001b[0m daldl_kmu \u001b[38;5;241m=\u001b[39m build_daldl_model(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)  \u001b[38;5;66;03m# 6 classes for KMU-FED\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaldl_ck\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mck_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mck_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCK+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m train_and_evaluate(daldl_kmu, kmu_images, kmu_labels, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKMU-FED\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 172\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, images, labels, num_classes, dataset_name)\u001b[0m\n\u001b[1;32m    166\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((val_images, val_labels))\u001b[38;5;241m.\u001b[39mbatch(batch_size)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m    168\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m    169\u001b[0m              loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    170\u001b[0m              metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 172\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_images)\n\u001b[1;32m    175\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(val_preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_8_1/csa_layer_9_1/mul defined at (most recent call last):\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 190, in <module>\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 172, in train_and_evaluate\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 116, in call\n\nDetected at node functional_8_1/csa_layer_9_1/mul defined at (most recent call last):\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 190, in <module>\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 172, in train_and_evaluate\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/Users/adicadi/Desktop/BTUBooks/ResearchModule/Research_Implementation/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/var/folders/kv/n_l7c5vj0bnc98gjc9byp0sm0000gn/T/ipykernel_88697/3891184482.py\", line 116, in call\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Incompatible shapes: [14528,227,227,1] vs. [64,227,227,16]\n\t [[{{node functional_8_1/csa_layer_9_1/mul}}]]\n\t [[StatefulPartitionedCall/functional_8_1/dense_37_1/Softmax/_336]]\n  (1) INVALID_ARGUMENT:  Incompatible shapes: [14528,227,227,1] vs. [64,227,227,16]\n\t [[{{node functional_8_1/csa_layer_9_1/mul}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_131258]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import kagglehub\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Download datasets\n",
    "ck_path = kagglehub.dataset_download(\"davilsena/ckdataset\")\n",
    "kmu_path = kagglehub.dataset_download(\"anandpanajkar/kmu-fed\")\n",
    "print(\"Path to CK+ dataset files:\", ck_path)\n",
    "print(\"Path to KMU-FED dataset files:\", kmu_path)\n",
    "\n",
    "# Debug: Print directory contents\n",
    "print(\"CK+ directory contents:\", os.listdir(ck_path))\n",
    "print(\"KMU-FED directory contents:\", os.listdir(kmu_path))\n",
    "\n",
    "# Load CK+ dataset from CSV with pixel data\n",
    "def load_ck_dataset(data_path):\n",
    "    csv_file = next((os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith('.csv')), None)\n",
    "    if not csv_file:\n",
    "        raise ValueError(f\"No CSV file found in {data_path}\")\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"CSV columns in {csv_file}: {df.columns.tolist()}\")\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        pixel_str = row['pixels'].split()\n",
    "        pixel_values = np.array([int(p) for p in pixel_str], dtype=np.uint8)\n",
    "        img_size = int(np.sqrt(len(pixel_values)))  # Assuming square image\n",
    "        if img_size * img_size != len(pixel_values):\n",
    "            raise ValueError(f\"Pixel data for row {index} cannot be reshaped into a square image\")\n",
    "        img = pixel_values.reshape(img_size, img_size, 1)\n",
    "        img = tf.image.resize(img, [227, 227])\n",
    "        img = tf.image.grayscale_to_rgb(img)\n",
    "        img = img / 255.0\n",
    "        images.append(img)\n",
    "        labels.append(int(row['emotion']))\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(f\"Loaded {len(images)} images from {data_path}\")\n",
    "    return images, labels\n",
    "\n",
    "# Load KMU-FED dataset from image files\n",
    "def load_kmu_dataset(data_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {'AN': 0, 'DI': 1, 'FE': 2, 'HA': 3, 'SA': 4, 'SU': 5}  # 6 classes for KMU-FED\n",
    "    \n",
    "    for filename in os.listdir(data_path):\n",
    "        if filename.endswith('.jpg'):\n",
    "            emotion = filename.split('_')[1]\n",
    "            if emotion in label_map:\n",
    "                img_path = os.path.join(data_path, filename)\n",
    "                img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "                img_array = np.array(img)\n",
    "                height, width = img.size  # Get actual dimensions\n",
    "                img_array = img_array.reshape(height, width, 1)  # Reshape to original size with channel\n",
    "                img = tf.image.resize(img_array, [227, 227])  # Resize to model input\n",
    "                img = tf.image.grayscale_to_rgb(img)  # Convert to RGB\n",
    "                img = img / 255.0  # Normalize\n",
    "                images.append(img)\n",
    "                labels.append(label_map[emotion])\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(f\"Loaded {len(images)} images from {data_path} with shape {images.shape[1:]}\")\n",
    "    return images, labels\n",
    "# Custom layer for Hybrid Channel Attention (HCA)\n",
    "class HCALayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_groups=32, **kwargs):\n",
    "        super(HCALayer, self).__init__(**kwargs)\n",
    "        self.max_groups = max_groups\n",
    "        self.group_norm = None\n",
    "        self.conv1d = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1]\n",
    "        num_groups = min(channels, self.max_groups)\n",
    "        self.group_norm = tf.keras.layers.GroupNormalization(groups=num_groups)\n",
    "        self.conv1d = tf.keras.layers.Conv1D(1, kernel_size=3, padding='same', activation='sigmoid')\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.group_norm(inputs)\n",
    "        x_mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "        x_mean = tf.squeeze(x_mean, axis=[1, 2])\n",
    "        x_mean = tf.expand_dims(x_mean, axis=1)\n",
    "        x_att = self.conv1d(x_mean)\n",
    "        x_att = tf.repeat(x_att, inputs.shape[1] * inputs.shape[2], axis=1)\n",
    "        x_att = tf.reshape(x_att, [-1, inputs.shape[1], inputs.shape[2], 1])\n",
    "        return inputs * x_att\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "# Custom layer for Coordinate Space Attention (CSA)\n",
    "class CSALayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CSALayer, self).__init__(**kwargs)\n",
    "        self.conv = tf.keras.layers.Conv2D(1, (3, 3), padding='same', activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h_pool = tf.reduce_mean(inputs, axis=2, keepdims=True)\n",
    "        w_pool = tf.reduce_mean(inputs, axis=1, keepdims=True)\n",
    "        h_pool = tf.reshape(h_pool, [-1, 1, 1, inputs.shape[-1]])\n",
    "        w_pool = tf.reshape(w_pool, [-1, 1, 1, inputs.shape[-1]])\n",
    "        attn = tf.keras.layers.Concatenate(axis=-1)([h_pool, w_pool])\n",
    "        attn = self.conv(attn)\n",
    "        attn = tf.repeat(tf.repeat(attn, inputs.shape[1], axis=1), inputs.shape[2], axis=2)\n",
    "        return inputs * attn\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "# SqueezeNext bottleneck block\n",
    "def squeeze_next_block(x, filters, strides=1):\n",
    "    x_shortcut = x\n",
    "    x = tf.keras.layers.Conv2D(filters // 2, (1, 1), activation='relu6', padding='same')(x)\n",
    "    x = tf.keras.layers.DepthwiseConv2D((3, 3), strides=strides, padding='same', activation='relu6')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters // 2, (1, 3), padding='same', activation='relu6')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters // 2, (3, 1), padding='same', activation='relu6')(x)\n",
    "    x = HCALayer(max_groups=32)(x)\n",
    "    x = CSALayer()(x)\n",
    "    x = tf.keras.layers.Conv2D(filters, (1, 1), activation='relu6', padding='same')(x)\n",
    "    if strides != 1 or x_shortcut.shape[-1] != filters:\n",
    "        x_shortcut = tf.keras.layers.Conv2D(filters, (1, 1), strides=strides, padding='same')(x_shortcut)\n",
    "    x = tf.keras.layers.Add()([x, x_shortcut])\n",
    "    return x\n",
    "\n",
    "# Define DALDL model with SqueezeNext backbone\n",
    "def build_daldl_model(num_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=(227, 227, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu6', padding='same')(inputs)\n",
    "    x = squeeze_next_block(x, filters=32)\n",
    "    x = squeeze_next_block(x, filters=64, strides=2)\n",
    "    x = squeeze_next_block(x, filters=128, strides=2)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu6')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model, images, labels, num_classes, dataset_name):\n",
    "    k_folds = 5\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "    \n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    accuracies, f1_scores = [], []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(images)):\n",
    "        print(f'Fold {fold + 1}/{k_folds} for {dataset_name}')\n",
    "        train_images, val_images = images[train_idx], images[val_idx]\n",
    "        train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "        \n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, verbose=1)\n",
    "        \n",
    "        val_preds = model.predict(val_images)\n",
    "        val_preds = np.argmax(val_preds, axis=1)\n",
    "        accuracies.append(accuracy_score(val_labels, val_preds))\n",
    "        f1_scores.append(f1_score(val_labels, val_preds, average='weighted'))\n",
    "    \n",
    "    print(f'{dataset_name} - Average Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}')\n",
    "    print(f'{dataset_name} - Average F1-Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}')\n",
    "\n",
    "# Load datasets\n",
    "ck_images, ck_labels = load_ck_dataset(ck_path)\n",
    "kmu_images, kmu_labels = load_kmu_dataset(kmu_path)\n",
    "\n",
    "# Build and train models\n",
    "daldl_ck = build_daldl_model(num_classes=7)  # 7 classes for CK+\n",
    "daldl_kmu = build_daldl_model(num_classes=6)  # 6 classes for KMU-FED\n",
    "\n",
    "train_and_evaluate(daldl_ck, ck_images, ck_labels, num_classes=7, dataset_name='CK+')\n",
    "train_and_evaluate(daldl_kmu, kmu_images, kmu_labels, num_classes=6, dataset_name='KMU-FED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
